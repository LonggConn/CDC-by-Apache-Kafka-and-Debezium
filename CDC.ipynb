{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a03abd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import library\n",
    "from kafka import KafkaConsumer\n",
    "from kafka import TopicPartition\n",
    "import json\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "import time\n",
    "import os\n",
    "from datetime import datetime\n",
    "from sqlalchemy.types import NVARCHAR, DECIMAL\n",
    "from multiprocessing import Pool\n",
    "from multiprocessing import Process\n",
    "import logging\n",
    "import time\n",
    "from sqlalchemy.engine import URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71f200b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_config_from_file(file_dir):\n",
    "    with open(file_dir) as f:\n",
    "        lines = f.readlines()\n",
    "        f.close()\n",
    "    return lines[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fd56870",
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_table_name_from_file(file_dir):\n",
    "    list_table_name = []\n",
    "    with open(file_dir) as f:\n",
    "        lines = f.readlines()\n",
    "        f.close()\n",
    "    list_table_tmp = lines[0].split(\",\")\n",
    "    for item in list_table_tmp:\n",
    "        if(item[0] == ' '):\n",
    "            item = item[1:]\n",
    "        list_table_name.append(item)\n",
    "    f.close()\n",
    "    return list_table_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "311a46f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_dt_col_name_from_file(file_dir):\n",
    "    date_col = []\n",
    "    with open(file_dir, encoding=\"utf8\") as f:\n",
    "        lines = f.readlines()\n",
    "        f.close()\n",
    "    list_col_tmp = lines[0].split(\",\")\n",
    "    for item in list_col_tmp:\n",
    "        if(item[0] == ' '):\n",
    "            item = item[1:]\n",
    "        date_col.append(item)\n",
    "    f.close()\n",
    "    return date_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "631d73a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_table_name(df):\n",
    "    source = pd.DataFrame([df.loc[0,'source']])\n",
    "    table_name = source.loc[0,'table']\n",
    "    return table_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "195baf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#take topic name\n",
    "def take_list_topic_name(list_table_name, prefix, database_source):\n",
    "    list_topic = []\n",
    "    for table_name in list_table_name:\n",
    "        topic_name = f'{prefix}.{database_source}.{table_name}'\n",
    "        list_topic.append(topic_name)\n",
    "    return list_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d07fc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read json data to dataframe\n",
    "def read_json_to_df(json):\n",
    "    data = pd.DataFrame([json])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab2bac02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_time():\n",
    "    now = datetime.now()\n",
    "    # dd/mm/YY H:M:S\n",
    "    dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "    return dt_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f9df32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_data(json,table_name,date_col, decimal_col, database_source, engine):\n",
    "    #Take new data\n",
    "    cdc_table = pd.DataFrame(json) \n",
    "    txt_cols = cdc_table.select_dtypes(include = ['object']).columns.values.tolist()\n",
    "    temp_dec = set(decimal_col)\n",
    "    nvarchar_col = [x for x in txt_cols if x not in temp_dec]\n",
    "    #Change nano epoch time to datetime\n",
    "    for col in cdc_table.columns:\n",
    "        if(col in date_col):\n",
    "            for i in cdc_table.index:\n",
    "                try:\n",
    "                    epoch_time = cdc_table.loc[i, col]\n",
    "                    dt_obj = datetime.utcfromtimestamp(epoch_time/1000)\n",
    "                    cdc_table.loc[i, col] = dt_obj\n",
    "                except Exception as e:\n",
    "                    cdc_table.loc[i,col] = None\n",
    "            cdc_table[col] = pd.to_datetime(cdc_table[col],errors='coerce')\n",
    "    \n",
    "    nvarchar = {col_name: NVARCHAR for col_name in nvarchar_col}\n",
    "    decimal = {decimal_name: DECIMAL for decimal_name in decimal_col}\n",
    "    change_dtype = {**nvarchar, **decimal}\n",
    "    \n",
    "    for i in range(600):  # If load fails due to a deadlock, try 600 more times\n",
    "        try:\n",
    "            cdc_table.to_sql(f'{table_name}', \n",
    "                             engine, \n",
    "                             if_exists='append', \n",
    "                             index = False, \n",
    "                             dtype = change_dtype)\n",
    "            f = open(f\"CDC_logs\\cdc_log_{database_source}_{table_name}_Insert.txt\", \"a\")\n",
    "            for i in cdc_table.index:\n",
    "                f.write(f\"{table_name}\\tID\\t{cdc_table.loc[i,'ID']}\\t{take_time()}\\tInsert\\n\")\n",
    "            f.close()\n",
    "            return\n",
    "        except Exception as ex:\n",
    "            if (i == 599):\n",
    "                f = open(f\"CDC_logs\\cdc_log_{database_source}_{table_name}_Error.txt\", \"a\")\n",
    "                for i in cdc_table.index:\n",
    "                    f.write(f\"{table_name}\\tID\\t{cdc_table.loc[i,'ID']}\\t{take_time()}\\tInsert\\n\")\n",
    "                f.close()\n",
    "                return\n",
    "            time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a79e875",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_data(json,table_name,date_col, decimal_col, database_source, engine):\n",
    "    cdc_table = pd.DataFrame(json) \n",
    "    txt_cols = cdc_table.select_dtypes(include = ['object']).columns.values.tolist()\n",
    "    temp_dec = set(decimal_col)\n",
    "    nvarchar_col = [x for x in txt_cols if x not in temp_dec]\n",
    "    #string set by loop\n",
    "    set_str = \"SET\"\n",
    "    for col in cdc_table.columns:\n",
    "        set_str = set_str + f\" {col} = td.{col},\\n\" #SQL command\n",
    "        if(col in date_col):\n",
    "            for i in cdc_table.index:\n",
    "                try:\n",
    "                    epoch_time = cdc_table.loc[i, col]\n",
    "                    dt_obj = datetime.utcfromtimestamp(epoch_time/1000)\n",
    "                    cdc_table.loc[i, col] = dt_obj\n",
    "                except Exception as e:\n",
    "                    cdc_table.loc[i,col] = None\n",
    "            cdc_table[col] = pd.to_datetime(cdc_table[col],errors='coerce')\n",
    "            \n",
    "    sql = f\"UPDATE dbo.{table_name}\\n\" + set_str[:-2] + f\"\\nFROM temp_{table_name}_update td \" +f\"WHERE dbo.{table_name}.ID = td.ID\"\n",
    "    \n",
    "    #delete temp table after complete\n",
    "    sql_del_temp = f\"Drop table temp_{table_name}_update\"\n",
    "        \n",
    "    for i in range(600):  # If load fails due to a deadlock, try 600 more times\n",
    "        try:\n",
    "            cdc_table.to_sql(f'temp_{table_name}_update', \n",
    "                             engine, \n",
    "                             if_exists='replace', \n",
    "                             index = False, \n",
    "                             dtype = change_dtype)\n",
    "        except Exception as ex:\n",
    "            if (i == 599):\n",
    "                f = open(f\"CDC_logs\\cdc_log_{database_source}_{table_name}_Error.txt\", \"a\")\n",
    "                for i in cdc_table.index:\n",
    "                    f.write(f\"{table_name}\\tID\\t{cdc_table.loc[i,'ID']}\\t{take_time()}\\tUpdate\\n\")\n",
    "                f.close()\n",
    "                return\n",
    "            time.sleep(0.1)   \n",
    "                \n",
    "    #run sql command\n",
    "    with engine.begin() as conn:\n",
    "        for i in range(600):  # If load fails due to a deadlock, try 600 more times\n",
    "            try:\n",
    "                conn.execute(text(sql)) #execute the update\n",
    "            except Exception as ex:\n",
    "                if (i == 599):\n",
    "                    f = open(f\"CDC_logs\\cdc_log_{database_source}_{table_name}_Error.txt\", \"a\")\n",
    "                    for i in cdc_table.index:\n",
    "                        f.write(f\"{table_name}\\tID\\t{cdc_table.loc[i,'ID']}\\t{take_time()}\\tUpdate\\n\")\n",
    "                    f.close()\n",
    "                    return\n",
    "                time.sleep(0.1)\n",
    "                \n",
    "        for i in range(600):  # If load fails due to a deadlock, try 600 more times\n",
    "            try:            \n",
    "                conn.execute(text(sql_del_temp)) #execute the delete\n",
    "                f = open(f\"CDC_logs\\cdc_log_{database_source}_{table_name}_Update.txt\", \"a\")\n",
    "                for i in cdc_table.index:\n",
    "                    f.write(f\"{table_name}\\tID\\t{cdc_table.loc[i,'ID']}\\t{take_time()}\\tUpdate\\n\")\n",
    "                f.close()\n",
    "                return\n",
    "            except Exception as ex:\n",
    "                if (i == 599):\n",
    "                    f = open(f\"CDC_logs\\cdc_log_{database_source}_Error.txt\", \"a\")\n",
    "                    for i in cdc_table.index:\n",
    "                        f.write(f\"{table_name}\\tID\\t{cdc_table.loc[i,'ID']}\\t{take_time()}\\tUpdate\\n\")\n",
    "                    f.close()\n",
    "                    return\n",
    "                time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfe7e377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_data(json,table_name,date_col, decimal_col, database_source, engine):\n",
    "    cdc_table = pd.DataFrame(json)\n",
    "    index = cdc_table['ID']\n",
    "    index_tuple = tuple(index)\n",
    "    sql = f\"DELETE FROM dbo.{table_name} WHERE dbo.{table_name}.ID in {index_tuple}\"\n",
    "\n",
    "    with engine.begin() as conn:\n",
    "        for i in range(600):  # If load fails due to a deadlock, try 600 more times\n",
    "            try:\n",
    "                conn.execute(text(sql))\n",
    "                f = open(f\"CDC_logs\\cdc_log_{database_source}_{table_name}_Delete.txt\", \"a\", encoding=\"utf-8\")\n",
    "                for i in cdc_table.index:\n",
    "                    f.write(f\"{table_name}\\tID\\t{cdc_table.loc[i,'ID']}\\t{take_time()}\\tDelete\\n\")\n",
    "                f.close()\n",
    "                return\n",
    "            except Exception as ex:\n",
    "                if (i == 599):\n",
    "                    f = open(f\"CDC_logs\\cdc_log_{database_source}_{table_name}_Error.txt\", \"a\")\n",
    "                    for i in cdc_table.index:\n",
    "                        f.write(f\"{table_name}\\tID\\t{cdc_table.loc[i,'ID']}\\t{take_time()}\\tDelete\\n\")\n",
    "                    f.close()\n",
    "                    return\n",
    "                time.sleep(0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c398c6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use file table to take all table\n",
    "def all_table_name(file_dir_table):\n",
    "    try:\n",
    "        list_table_name = take_table_name_from_file(file_dir_table)\n",
    "    except IndexError:\n",
    "        list_table_name = []\n",
    "    return list_table_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "333368e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the topic list\n",
    "def Consumer(table_name, bootstrap_servers, group_id, prefix, database_source, date_col, decimal_col, username_destination, password_destination, hostname_destination, port_destination, database_destination):\n",
    "    #define the connect engine\n",
    "    connection_url = URL.create(\n",
    "        \"mssql+pyodbc\",\n",
    "        username=username_destination,\n",
    "        password=password_destination,\n",
    "        host=hostname_destination,\n",
    "        port=port_destination,\n",
    "        database=database_destination,\n",
    "        query={\n",
    "            \"driver\": \"ODBC Driver 17 for SQL Server\"\n",
    "        },\n",
    "    )\n",
    "    engine = create_engine(connection_url, isolation_level=\"READ_UNCOMMITTED\", fast_executemany=True).connect()\n",
    "    \n",
    "    list_topic = take_list_topic_name([table_name], prefix, database_source)\n",
    "    \n",
    "    print(f'start consumer for {table_name}')\n",
    "    # Initialize consumer variable\n",
    "    consumer = KafkaConsumer (list_topic[0], \n",
    "                              bootstrap_servers = bootstrap_servers,\n",
    "                              auto_offset_reset='earliest', \n",
    "                              enable_auto_commit=True,\n",
    "                              auto_commit_interval_ms=10000,\n",
    "                              group_id=f'{group_id}_table_{table_name[4:]}',\n",
    "                              max_partition_fetch_bytes=10485760)\n",
    "    \n",
    "    list_msg_insert = []\n",
    "    list_msg_delete = []\n",
    "    list_msg_update = []\n",
    "    \n",
    "    for msg in consumer:\n",
    "        try:\n",
    "            #take current and end offset\n",
    "            partitions = [TopicPartition(list_topic[0], p) for p in consumer.partitions_for_topic(list_topic[0])]\n",
    "            last_offset_per_partition = consumer.end_offsets(partitions)\n",
    "            end_offset = list(last_offset_per_partition.values())[0]\n",
    "            current_offset = consumer.position(TopicPartition(topic=list_topic[0], partition=0))\n",
    "            \n",
    "            #Read data from comsumer\n",
    "            data = json.loads(msg.value)\n",
    "            \n",
    "            #take change data\n",
    "            decode_json = data.get('payload')\n",
    "            \n",
    "            #take before and after\n",
    "            before_json = decode_json.get('before')\n",
    "            after_json = decode_json.get('after')\n",
    "            \n",
    "            #take table name\n",
    "#             df = pd.DataFrame()\n",
    "#             table_name = take_table_name(df)\n",
    "            table_name_add = table_name[4:]\n",
    "    \n",
    "            #Check action\n",
    "            if(before_json == None and after_json == None):\n",
    "                continue\n",
    "            elif (before_json == None):\n",
    "                list_msg_insert.append(after_json)\n",
    "            elif (after_json == None):\n",
    "                list_msg_delete.append(before_json)\n",
    "            else:\n",
    "                list_msg_update.append(after_json)\n",
    "            \n",
    "            if current_offset >= end_offset:\n",
    "                if list_msg_insert:\n",
    "                    insert_data(list_msg_insert,table_name_add,date_col, decimal_col, database_source, engine)\n",
    "                    list_msg_insert = []\n",
    "                if list_msg_delete:\n",
    "                    delete_data(list_msg_delete,table_name_add,date_col, decimal_col, database_source, engine)\n",
    "                    list_msg_delete = []\n",
    "                if list_msg_update:\n",
    "                    update_data(list_msg_update,table_name_add,date_col, decimal_col, database_source, engine)\n",
    "                    list_msg_update = []\n",
    "              \n",
    "        #Temporary use try except to avoid bug when read null message\n",
    "        except TypeError:\n",
    "            time.sleep(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa046aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process Ended with an error or a terminate  dbo.AccountGroups\n",
      "Process Ended with an error or a terminate  dbo.AssignmentDetails\n",
      "Process Ended with an error or a terminate  dbo.Assignments\n",
      "Process Ended with an error or a terminate  dbo.BODetails\n",
      "Process Ended with an error or a terminate  dbo.BOKinds\n",
      "Process Ended with an error or a terminate  dbo.BOPeriodDetails\n",
      "Process Ended with an error or a terminate  dbo.BOPeriods\n",
      "Process Ended with an error or a terminate  dbo.Branches\n",
      "Process Ended with an error or a terminate  dbo.BudgetStandards\n",
      "Process Ended with an error or a terminate  dbo.BusinessOpportunities\n",
      "Process Ended with an error or a terminate  dbo.BusinessPlans\n",
      "Process Ended with an error or a terminate  dbo.ChangeRequests\n",
      "Process Ended with an error or a terminate  dbo.ConsultantDetails\n",
      "Process Ended with an error or a terminate  dbo.Consultants\n",
      "Process Ended with an error or a terminate  dbo.ContractDetails\n",
      "Process Ended with an error or a terminate  dbo.ContractLockStatus\n",
      "Process Ended with an error or a terminate  dbo.Contracts\n",
      "Process Ended with an error or a terminate  dbo.ContractTypes\n",
      "Process Ended with an error or a terminate  dbo.CostForGuarantees\n",
      "Process Ended with an error or a terminate  dbo.CostForMoneys\n",
      "Process Ended with an error or a terminate  dbo.CostMandayBlockPrices\n",
      "Process Ended with an error or a terminate  dbo.Customers\n",
      "Process Ended with an error or a terminate  dbo.CustomerTypes\n",
      "Process Ended with an error or a terminate  dbo.DecisionDetails\n",
      "Process Ended with an error or a terminate  dbo.EmployeeTypePrices\n",
      "Process Ended with an error or a terminate  dbo.EmployeeTypes\n",
      "Process Ended with an error or a terminate  dbo.EmployeeTypeVersions\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 55\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m list_process\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m     54\u001b[0m     (p, t) \u001b[38;5;241m=\u001b[39m list_process[n]\n\u001b[1;32m---> 55\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m  p\u001b[38;5;241m.\u001b[39mexitcode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m p\u001b[38;5;241m.\u001b[39mis_alive(): \u001b[38;5;66;03m# Not finished and not running\u001b[39;00m\n\u001b[0;32m     57\u001b[0m         \u001b[38;5;28mprint\u001b[39m(t, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is gone as if never born!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #file directory\n",
    "    file_dir_ip_and_group = 'Config/config_ip_and_group_id.txt'\n",
    "    file_dir_dt_col = 'Table/dt_col.txt'\n",
    "    file_dir_dc_col = 'Table/dc_col.txt'\n",
    "    file_dir_config_source = 'Config/config_source.txt'\n",
    "    file_dir_config_destination = 'Config/config_destination.txt'\n",
    "    \n",
    "    #take config source\n",
    "    username_source, password_source, hostname_source, port_source, database_source, prefix \\\n",
    "    = take_config_from_file(file_dir_config_source).split('\\t')\n",
    "    \n",
    "    #take config destination\n",
    "    username_destination, password_destination, hostname_destination, port_destination, database_destination \\\n",
    "    = take_config_from_file(file_dir_config_destination).split('\\t')\n",
    "    \n",
    "    #take config host and group id\n",
    "    ip_host, group_id = take_config_from_file(file_dir_ip_and_group).split('\\t')\n",
    "    \n",
    "    #take columns datetime\n",
    "    date_col = take_dt_col_name_from_file(file_dir_dt_col)\n",
    "    \n",
    "    #take object columns\n",
    "    decimal_col = take_dt_col_name_from_file(file_dir_dc_col)\n",
    "    # Define server with port\n",
    "    bootstrap_servers = [f'{ip_host}:9092',f'{ip_host}:9093',f'{ip_host}:9094']\n",
    "    \n",
    "    #Create process\n",
    "    file_dir_table = f'Table/cdc_table.txt'\n",
    "    list_table_name = all_table_name(file_dir_table)\n",
    "    list_process = {}\n",
    "    id_process = 0\n",
    "    \n",
    "        \n",
    "    #create log\n",
    "    for table_name in list_table_name:\n",
    "        for action in ['Insert','Update','Delete','Error']:\n",
    "            file_dir_log = f'CDC_logs/cdc_log_{database_source}_{table_name[4:]}_{action}.txt'\n",
    "            if (os.path.isfile(file_dir_log)) == False:\n",
    "                f = open(f\"{file_dir_log}\", \"a\", encoding=\"utf-8\")\n",
    "                f.write(\"Table\\tID\\tcreate_at\\ttype\\n\")\n",
    "                f.close()\n",
    "\n",
    "    #start process\n",
    "    for table_name in list_table_name:\n",
    "        process = Process(target=Consumer, args=(table_name, bootstrap_servers, group_id, prefix, database_source, date_col, decimal_col, username_destination, password_destination, hostname_destination, port_destination, database_destination))\n",
    "        process.start()\n",
    "        list_process[id_process] = (process,table_name) #Save the process with it's name\n",
    "        id_process += 1\n",
    "    \n",
    "    #Restart dead process\n",
    "    while len(list_process) > 0:\n",
    "        for n in list_process.keys():\n",
    "            (p, t) = list_process[n]\n",
    "            time.sleep(0.5)\n",
    "            if  p.exitcode is None and not p.is_alive(): # Not finished and not running\n",
    "                print(t, ' is gone as if never born!')\n",
    "                process = Process(target=Consumer, args=(t, bootstrap_servers, group_id, prefix, database_source, date_col, decimal_col, username_destination, password_destination, hostname_destination, port_destination, database_destination))\n",
    "                process.start()\n",
    "                list_process[n] = (process,t)\n",
    "            elif p.exitcode is None: #process running\n",
    "                continue\n",
    "            elif p.exitcode < 0 or not p.is_alive():\n",
    "                print ('Process Ended with an error or a terminate ', t)\n",
    "                process = Process(target=Consumer, args=(t, bootstrap_servers, group_id, prefix, database_source, date_col, decimal_col, username_destination, password_destination, hostname_destination, port_destination, database_destination))\n",
    "                process.start()\n",
    "                list_process[n] = (process,t)\n",
    "            else:\n",
    "                print (t, ' finished')\n",
    "                p.join() # Allow tidyup\n",
    "                del processes[n] # Removed finished items from the dictionary \n",
    "                # When none are left then loop will end\n",
    "                \n",
    "    print('Finish')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
