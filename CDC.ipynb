{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a03abd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import library\n",
    "from kafka import KafkaConsumer\n",
    "import json\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "import time\n",
    "import os\n",
    "from datetime import datetime\n",
    "from urllib.parse import quote_plus\n",
    "from sqlalchemy.types import NVARCHAR\n",
    "from multiprocessing import Pool\n",
    "from multiprocessing import Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71f200b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_config_from_file(file_dir):\n",
    "    with open(file_dir) as f:\n",
    "        lines = f.readlines()\n",
    "        f.close()\n",
    "    return lines[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fd56870",
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_table_name_from_file(file_dir):\n",
    "    list_table_name = []\n",
    "    with open(file_dir) as f:\n",
    "        lines = f.readlines()\n",
    "        f.close()\n",
    "    list_table_tmp = lines[0].split(\",\")\n",
    "    for item in list_table_tmp:\n",
    "        if(item[0] == ' '):\n",
    "            item = item[1:]\n",
    "        list_table_name.append(item)\n",
    "    f.close()\n",
    "    return list_table_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "311a46f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_dt_col_name_from_file(file_dir):\n",
    "    date_col = []\n",
    "    with open(file_dir) as f:\n",
    "        lines = f.readlines()\n",
    "        f.close()\n",
    "    list_col_tmp = lines[0].split(\",\")\n",
    "    for item in list_col_tmp:\n",
    "        if(item[0] == ' '):\n",
    "            item = item[1:]\n",
    "        date_col.append(item)\n",
    "    f.close()\n",
    "    return date_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "631d73a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_table_name(df):\n",
    "    source = pd.DataFrame([df.loc[0,'source']])\n",
    "    table_name = source.loc[0,'table']\n",
    "    return table_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "195baf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#take topic name\n",
    "def take_list_topic_name(list_table_name, prefix, database_source):\n",
    "    list_topic = []\n",
    "    for table_name in list_table_name:\n",
    "        topic_name = f'{prefix}.{database_source}.{table_name}'\n",
    "        list_topic.append(topic_name)\n",
    "    return list_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d07fc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read json data to dataframe\n",
    "def read_json_to_df(json):\n",
    "    data = pd.DataFrame([json])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab2bac02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_time():\n",
    "    now = datetime.now()\n",
    "    # dd/mm/YY H:M:S\n",
    "    dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "    return dt_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f9df32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_data(df,table_name,date_col, database_source, engine):\n",
    "    #Take new data\n",
    "    cdc_table = pd.DataFrame([df.loc[0,'after']]) \n",
    "    txt_cols = cdc_table.select_dtypes(include = ['object']).columns.values.tolist()\n",
    "    #Change nano epoch time to datetime\n",
    "    for col in cdc_table.columns:\n",
    "        if(col in date_col):\n",
    "            try:\n",
    "                epoch_time = cdc_table.loc[0, col]\n",
    "                dt_obj = datetime.utcfromtimestamp(epoch_time/1000)\n",
    "                cdc_table.loc[0, col] = dt_obj\n",
    "            except Exception as e:\n",
    "                cdc_table.loc[0,col] = None\n",
    "                cdc_table[col] = pd.to_datetime(cdc_table[col],errors='coerce')\n",
    "    cdc_table.to_sql(f'{table_name}', engine, if_exists='append', index = False, dtype = {col_name: NVARCHAR for col_name in txt_cols}) \n",
    "    f = open(f\".\\CDC_logs\\cdc_log_{database_source}_Insert.txt\", \"a\")\n",
    "    f.write(f\"{table_name}\\tID\\t{cdc_table.loc[0,'ID']}\\t{take_time()}\\tInsert\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a79e875",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_data(df,table_name,date_col, database_source, engine):\n",
    "    cdc_table = pd.DataFrame([df.loc[0,'after']])\n",
    "    txt_cols = cdc_table.select_dtypes(include = ['object']).columns.values.tolist()\n",
    "    #string set by loop\n",
    "    set_str = \"SET\"\n",
    "    for col in cdc_table.columns:\n",
    "        set_str = set_str + f\" {col} = t.{col},\\n\" #SQL command\n",
    "        if(col in date_col):\n",
    "            try:\n",
    "                epoch_time = cdc_table.loc[0, col]\n",
    "                dt_obj = datetime.utcfromtimestamp(epoch_time/1000)\n",
    "                cdc_table.loc[0, col] = dt_obj\n",
    "            except Exception as e:\n",
    "                cdc_table.loc[0,col] = None\n",
    "                cdc_table[col] = pd.to_datetime(cdc_table[col],errors='coerce')\n",
    "            \n",
    "    sql = f\"UPDATE dbo.{table_name}\\n\" + set_str[:-2] + \"\\nFROM temp t \" +f\"WHERE dbo.{table_name}.ID = t.ID\"\n",
    "    \n",
    "    #delete temp table after complete\n",
    "    sql_del_temp = \"Drop table temp\"\n",
    "        \n",
    "    #create temp table to reduce time to reconize columns type\n",
    "    cdc_table.to_sql('temp', engine, if_exists='replace', dtype = {col_name: NVARCHAR for col_name in txt_cols}, index = False)\n",
    "\n",
    "    #run sql command\n",
    "    with engine.begin() as conn:\n",
    "        conn.execute(text(sql))\n",
    "        conn.execute(text(sql_del_temp))\n",
    "        f = open(f\".\\CDC_logs\\cdc_log_{database_source}_Update.txt\", \"a\")\n",
    "        f.write(f\"{table_name}\\tID\\t{cdc_table.loc[0,'ID']}\\t{take_time()}\\tUpdate\\n\")\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfe7e377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_data(df,table_name, database_source, engine):\n",
    "    cdc_table = pd.DataFrame([df.loc[0,'before']])\n",
    "    \n",
    "    sql = f\"DELETE FROM dbo.{table_name} WHERE dbo.{table_name}.ID = {cdc_table.loc[0,'ID']}\"\n",
    "\n",
    "    with engine.begin() as conn:\n",
    "        conn.execute(text(sql))\n",
    "        f = open(f\".\\CDC_logs\\cdc_log_{database_source}_Delete.txt\", \"a\", encoding=\"utf-8\")\n",
    "        f.write(f\"{table_name}\\tID\\t{cdc_table.loc[0,'ID']}\\t{take_time()}\\tDelete\\n\")\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c398c6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use file table to take all table\n",
    "def all_table_name(file_dir_table):\n",
    "    try:\n",
    "        list_table_name = take_table_name_from_file(file_dir_table)\n",
    "    except IndexError:\n",
    "        list_table_name = []\n",
    "    return list_table_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "333368e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the topic list\n",
    "def Consumer(table_name, bootstrap_servers, group_id, prefix, database_source, date_col, username_destination, password_destination, hostname_destination, port_destination, database_destination):\n",
    "    #define the connect engine\n",
    "    password_destination = quote_plus(password_destination)\n",
    "    engine = create_engine(f'mssql+pymssql://{username_destination}:{password_destination}@{hostname_destination}:{port_destination}/{database_destination}') \n",
    "    \n",
    "    list_topic = take_list_topic_name([table_name], prefix, database_source)\n",
    "\n",
    "    # Initialize consumer variable\n",
    "    consumer = KafkaConsumer (list_topic[0], \n",
    "                              bootstrap_servers = bootstrap_servers,\n",
    "                              auto_offset_reset='earliest', \n",
    "                              enable_auto_commit=True,\n",
    "                              auto_commit_interval_ms=5000,\n",
    "                              group_id=f'{group_id}_table_{table_name[4:]}',\n",
    "                              max_partition_fetch_bytes=10485760)\n",
    "    \n",
    "    for msg in consumer:\n",
    "        try:\n",
    "        #Read data from comsumer\n",
    "            data = json.loads(msg.value)\n",
    "            df = read_json_to_df(data)\n",
    "            #Take change data\n",
    "            df = pd.DataFrame([df.loc[0,'payload']])\n",
    "            #take table name\n",
    "            table_name = take_table_name(df)\n",
    "            #Check action\n",
    "            if(df.loc[0,'before'] == None and df.loc[0,'after'] == None):\n",
    "                continue\n",
    "            elif (df.loc[0,'before'] == None):\n",
    "                insert_data(df,table_name,date_col, database_source, engine)\n",
    "            elif (df.loc[0,'after'] == None):\n",
    "                delete_data(df,table_name, database_source, engine)\n",
    "            else:\n",
    "                update_data(df,table_name,date_col, database_source, engine)\n",
    "        #Temporary use try except to avoid bug when read null message\n",
    "        except TypeError:\n",
    "            time.sleep(0.001) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa046aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #file directory\n",
    "    file_dir_ip_and_group = 'Config/config_ip_and_group_id.txt'\n",
    "    file_dir_dt_col = 'Table/dt_col.txt'\n",
    "    file_dir_config_source = 'Config/config_source.txt'\n",
    "    file_dir_config_destination = 'Config/config_destination.txt'\n",
    "    \n",
    "    #take config source\n",
    "    username_source, password_source, hostname_source, port_source, database_source, prefix \\\n",
    "    = take_config_from_file(file_dir_config_source).split('\\t')\n",
    "    \n",
    "    #take config destination\n",
    "    username_destination, password_destination, hostname_destination, port_destination, database_destination \\\n",
    "    = take_config_from_file(file_dir_config_destination).split('\\t')\n",
    "    \n",
    "    #take config host and group id\n",
    "    ip_host, group_id = take_config_from_file(file_dir_ip_and_group).split('\\t')\n",
    "    \n",
    "    #take columns datetime\n",
    "    date_col = take_dt_col_name_from_file(file_dir_dt_col)\n",
    "    \n",
    "    #create log\n",
    "    for action in ['Insert','Update','Delete']:\n",
    "        file_dir_log = f'CDC_logs/cdc_log_{database_source}_{action}.txt'\n",
    "        if (os.path.isfile(file_dir_log)) == False:\n",
    "            f = open(f\"{file_dir_log}\", \"a\", encoding=\"utf-8\")\n",
    "            f.write(\"Table\\tID\\tcreate_at\\ttype\\n\")\n",
    "            f.close()\n",
    "\n",
    "    # Define server with port\n",
    "    bootstrap_servers = [f'{ip_host}:9092',f'{ip_host}:9093',f'{ip_host}:9094']\n",
    "    \n",
    "    list_process = []\n",
    "    #Create process\n",
    "    file_dir_table = f'Table/cdc_table.txt'\n",
    "    list_table_name = all_table_name(file_dir_table)\n",
    "    for table_name in list_table_name:\n",
    "        process = Process(target=Consumer, args=(table_name, bootstrap_servers, group_id, prefix, database_source, date_col, username_destination, password_destination, hostname_destination, port_destination, database_destination))\n",
    "        list_process.append(process)\n",
    "    #start project\n",
    "    for process in list_process:\n",
    "        process.start()\n",
    "    #block main\n",
    "    for process in list_process:\n",
    "        process.join()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
